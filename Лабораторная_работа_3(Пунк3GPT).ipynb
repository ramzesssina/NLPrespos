{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2wTvOgryUiC4iW1KqgdYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramzesssina/NLPrespos/blob/main/%D0%9B%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_3(%D0%9F%D1%83%D0%BD%D0%BA3GPT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Пункт 3 - Создание GPT**"
      ],
      "metadata": {
        "id": "6khsjHWJCG_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mArDtGcvXXR"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    x = np.clip(x, -500, 500)\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(x):\n",
        "    fx = sigmoid(x)\n",
        "    return fx * (1 - fx)"
      ],
      "metadata": {
        "id": "afNNFYKIv7VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "    def __init__(self, input_size):\n",
        "        self.w = np.random.randn(input_size) * 0.1\n",
        "        self.b = 0.0\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        self.last_x = x\n",
        "        self.last_total = np.dot(x, self.w) + self.b\n",
        "        return sigmoid(self.last_total)\n",
        "\n",
        "    def train(self, grad_output, lr=0.01):\n",
        "        grad_total = deriv_sigmoid(self.last_total) * grad_output\n",
        "        self.w -= lr * grad_total * self.last_x\n",
        "        self.b -= lr * grad_total"
      ],
      "metadata": {
        "id": "ZpEBSt5Ow537"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head:\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, lr=0.01):\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.lr = lr\n",
        "\n",
        "        self.W_k = np.random.randn(embed_dim, hidden_dim) * 0.1\n",
        "        self.W_q = np.random.randn(embed_dim, hidden_dim) * 0.1\n",
        "        self.W_v = np.random.randn(embed_dim, hidden_dim) * 0.1\n",
        "\n",
        "        self.W_out = np.random.randn(hidden_dim, vocab_size) * 0.1\n",
        "        self.b_out = np.zeros((vocab_size,))\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        self.k = x @ self.W_k\n",
        "        self.q = x @ self.W_q\n",
        "        self.v = x @ self.W_v\n",
        "\n",
        "        self.wei = np.matmul(self.q, self.k.transpose(0, 2, 1)) / np.sqrt(self.hidden_dim)\n",
        "        mask = np.tril(np.ones((T, T)))\n",
        "        self.wei = np.where(mask == 1, self.wei, -1e9)\n",
        "        self.wei_softmax = self.softmax(self.wei)\n",
        "        self.out = np.matmul(self.wei_softmax, self.v)\n",
        "\n",
        "        self.logits = np.matmul(self.out, self.W_out) + self.b_out\n",
        "        self.probs = self.softmax(self.logits)\n",
        "        return self.probs\n",
        "\n",
        "    def train(self, dataset, targets, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            probs = self.forward(dataset)\n",
        "            loss = -np.mean(np.log(probs[np.arange(len(dataset))[:, None], np.arange(dataset.shape[1]), targets]))\n",
        "\n",
        "            dlogits = probs\n",
        "            dlogits[np.arange(len(dataset))[:, None], np.arange(dataset.shape[1]), targets] -= 1\n",
        "            dlogits /= len(dataset) * dataset.shape[1]\n",
        "\n",
        "            grad_W_out = self.out.reshape(-1, self.hidden_dim).T @ dlogits.reshape(-1, self.vocab_size)\n",
        "            grad_b_out = np.sum(dlogits, axis=(0, 1))\n",
        "\n",
        "            self.W_out -= self.lr * grad_W_out\n",
        "            self.b_out -= self.lr * grad_b_out\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "    def evaluate(self, text_ids, idx_to_char, embedding_matrix, steps=5, true_text=None, temperature=1.0):\n",
        "            generated_text = \"\".join([idx_to_char[i] for i in text_ids])\n",
        "            print(\"Начальный текст:\", generated_text)\n",
        "\n",
        "            for step in range(steps):\n",
        "                input_ids = np.array(text_ids[-4:])\n",
        "                embedded = embedding_matrix[input_ids].reshape(1, -1, self.embed_dim)\n",
        "                probs = self.forward(embedded)[0, -1]\n",
        "\n",
        "                probs = np.log(probs + 1e-8) / temperature\n",
        "                probs = np.exp(probs) / np.sum(np.exp(probs))\n",
        "\n",
        "                next_id = np.random.choice(len(probs), p=probs)\n",
        "                text_ids.append(next_id)\n",
        "                predicted_word = idx_to_char[next_id]\n",
        "                if true_text is not None and step + 1 < len(true_text):\n",
        "                    actual_word = true_text[step + 1]\n",
        "                    print(f\"Предсказанное слово: {predicted_word}, Реальное слово: {actual_word}\")\n",
        "                else:\n",
        "                    print(f\"Предсказанное слово: {predicted_word}\")"
      ],
      "metadata": {
        "id": "8GFejZeS0Ksb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"В мире технологий каждый день появляются новые возможности для саморазвития и карьерного роста. Важно не только следить за трендами, но и постоянно учиться, осваивая новые инструменты и подходы. Это особенно актуально для тех, кто стремится быть востребованным специалистом в сфере IT. Работая над своими проектами и развивая навыки, можно не только достичь успеха, но и найти себя в профессии, которая приносит удовлетворение.\"\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "seq_len = 4\n",
        "X = []\n",
        "Y = []"
      ],
      "metadata": {
        "id": "GePyUpDs31Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text) - seq_len):\n",
        "    seq = text[i:i+seq_len]\n",
        "    target = text[i+1:i+seq_len+1]\n",
        "    X.append([char_to_idx[c] for c in seq])\n",
        "    Y.append([char_to_idx[c] for c in target])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "rWYrMsWN4h2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Head(vocab_size, embed_dim=2, hidden_dim=8, lr=0.1)\n",
        "\n",
        "seq_len = 10\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(len(text) - seq_len):\n",
        "    seq = text[i:i+seq_len]\n",
        "    target = text[i+1:i+seq_len+1]\n",
        "    X.append([char_to_idx[c] for c in seq])\n",
        "    Y.append([char_to_idx[c] for c in target])"
      ],
      "metadata": {
        "id": "M16KicAW7gRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "embedding_dim = 2\n",
        "embedding_matrix = np.random.randn(vocab_size, embedding_dim) * 0.1\n",
        "X_embedded = embedding_matrix[X]\n",
        "\n",
        "model.train(X_embedded, Y, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1ZhPhbw7kG8",
        "outputId": "1b68de88-049b-4d84-fe6e-5a8d64e13880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 3.5836\n",
            "Epoch 100: Loss = 3.3189\n",
            "Epoch 200: Loss = 3.2007\n",
            "Epoch 300: Loss = 3.1476\n",
            "Epoch 400: Loss = 3.1193\n",
            "Epoch 500: Loss = 3.1023\n",
            "Epoch 600: Loss = 3.0912\n",
            "Epoch 700: Loss = 3.0835\n",
            "Epoch 800: Loss = 3.0779\n",
            "Epoch 900: Loss = 3.0737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_text = \"саморазвитие\"\n",
        "text_ids = [char_to_idx[ch] for ch in initial_text]\n",
        "\n",
        "true_text = text[len(initial_text):len(initial_text)+5]\n",
        "\n",
        "model.evaluate(text_ids, idx_to_char, embedding_matrix, true_text=true_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0JK8Q3m8IzY",
        "outputId": "773dd613-3d2a-4770-f45c-9e75004e6c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начальный текст: саморазвитие\n",
            "Предсказанное слово: и, Реальное слово: о\n",
            "Предсказанное слово: ж, Реальное слово: г\n",
            "Предсказанное слово: к, Реальное слово: и\n",
            "Предсказанное слово: ы, Реальное слово: й\n",
            "Предсказанное слово: о\n"
          ]
        }
      ]
    }
  ]
}